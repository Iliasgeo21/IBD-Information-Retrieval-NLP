![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)
![scikit--learn](https://img.shields.io/badge/scikit--learn-ML-yellow.svg)
![NLP](https://img.shields.io/badge/NLP-Biomedical-green.svg)
![License: MIT](https://img.shields.io/badge/License-MIT-lightgrey.svg)

# IBD-Information-Retrieval-NLP
Natural Language Processing pipeline for information retrieval on Inflammatory Bowel Diseases (IBD) using the PubMed 200k RCT dataset. Includes preprocessing, statistical and deep learning models (TF-IDF + SVM, Transformer embeddings), evaluation and visualization for biomedical text classification and analysis.
## Table of contents

â€¢	Project overview

â€¢	Dataset

â€¢	Repository structure

â€¢	Quickstart

â€¢	Reproducible pipelines

â€¢	Results

â€¢	Roadmap

â€¢	Cite / Thesis

â€¢	License

â€¢	Acknowledgments

## ğŸ¯ Project overview

The goal is to retrieve and classify biomedical text relevant to IBD and biological/therapeutic factors (e.g., anti-TNF) from research abstracts.
We:
1.	Parse and structure abstracts with line-level labels
2.	Explore label balance and text statistics
3.	Train baselines with TF-IDF + SVM
4.	Train neural models with pretrained sentence embeddings (Universal Sentence Encoder)
5.	Evaluate with accuracy/precision/recall, learning curves and confusion matrices
Why this matters: IBD literature is large and heterogeneous.
A clean IR+NLP pipeline helps surface clinically relevant evidence faster.

## ğŸ“‚ Dataset

â€¢	PubMed 200k RCT (train/dev/test files with section-level labels).

â€¢	Not included in the repo. Please download from its official source and place as:

data/

â”œâ”€â”€ train.txt

â”œâ”€â”€ dev.txt

â””â”€â”€ test.txt

Optionally you may keep a small sample in data/sample/ for quick runs.

## ğŸ§± Repository structure

This project follows a modular structure typical for machine learning and NLP pipelines:
.
â”œâ”€â”€ data/                     # <- place dataset files here (not tracked)

â”œâ”€â”€ notebooks/

â”‚   â””â”€â”€ Thesis.ipynb          # exploratory analysis & figures

â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ preprocessing.py      # text loading, parsing, cleaning

â”‚   â”œâ”€â”€ svm_model.py          # TF-IDF + SVM pipeline + grid search

â”‚   â”œâ”€â”€ use_model.py          # Sentence embeddings (USE) + dense head

â”‚   â””â”€â”€ utils.py              # metrics, plots, saving

â”œâ”€â”€ results/

â”‚   â”œâ”€â”€ confusion_matrices/

â”‚   â””â”€â”€ learning_curves/

â”œâ”€â”€ requirements.txt

â”œâ”€â”€ LICENSE

â””â”€â”€ README.md


## ğŸš€ Quickstart / Installation

1) Create environment
   
python -m venv .venv
# Windows: .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

pip install --upgrade pip
pip install -r requirements.txt

2) Prepare data

â€¢	Download PubMed 200k RCT and place train.txt, dev.txt, test.txt under data/.

4) Run (current state)
   
â€¢	Open notebooks/Thesis.ipynb and run all cells

or

â€¢	Run the SVM pipeline (after refactor)

python src/svm_model.py --data_dir data --out_dir results

â€¢	Run the sentence-embeddings pipeline (after refactor)

python src/use_model.py --data_dir data --out_dir results



## Reproducible pipelines

SVM (TF-IDF + class-balanced SVC)

â€¢	Text lemmatization & stop-word removal

â€¢	TF-IDF (1â€“2 n-grams, configurable features)

â€¢	SVC with class_weight='balanced'

â€¢	GridSearchCV across C, gamma, TF-IDF features

â€¢	Metrics: accuracy, weighted precision/recall

â€¢	Artifacts: learning curves, confusion matrix (saved to results/)

Sentence embeddings (USE)

â€¢	Pretrained Universal Sentence Encoder (TF Hub) as frozen encoder

â€¢	Dense head + dropout

â€¢	EarlyStopping & class weights for imbalance

â€¢	Metrics & confusion matrices exported to results/

## ğŸ“Š Results

### ğŸ“âœ¨ TF-IDF + SVM Model

The TF-IDF + SVM model achieved strong performance on structured biomedical abstracts from the PubMed 200k RCT dataset, especially in the **METHODS** and **RESULTS** categories.

**Classification Report (Validation Set)**

| Class        | Precision | Recall | F1-score | Support |
|--------------|----------:|-------:|--------:|--------:|
| BACKGROUND   | 0.46      | 0.61   | 0.53     | 533     |
| CONCLUSIONS  | 0.62      | 0.74   | 0.67     | 764     |
| METHODS      | 0.83      | 0.86   | 0.85     | 1028    |
| OBJECTIVE    | 0.74      | 0.58   | 0.65     | 596     |
| RESULTS      | 0.92      | 0.72   | 0.80     | 1100    |

**Validation Accuracy:** ~0.71  
**Macro F1-score:** ~0.70

#### ğŸ“ˆ Learning Curve
![SVM learning curve](src/results/figures/learning_curve_svm.png)

#### ğŸ”µ  Confusion Matrix
![SVM confusion matrix](src/results/figures/confusion_matrix_svm.png)

###  ğŸ§ âš¡ USE + Dense Model Results

#### âœ… Classification Metrics
| Class | Precision | Recall | F1-Score | Support |
|---|---|---|---|---|
| BACKGROUND | 0.53 | 0.59 | 0.56 | 501 |
| CONCLUSIONS | 0.65 | 0.70 | 0.67 | 704 |
| METHODS | 0.83 | 0.83 | 0.83 | 999 |
| OBJECTIVE | 0.70 | 0.65 | 0.67 | 592 |
| RESULTS | 0.85 | 0.80 | 0.82 | 1164 |
| **Accuracy** | - | - | **0.74** | **3960** |

#### ğŸ“ˆ Learning Curve
<img src="src/results/figures/learning_curve_use.png" width="500"/>

#### ğŸ”µ Confusion Matrices

**Validation Set**
<img src="src/results/figures/confusion_matrix_use_val.png" width="500"/>

**Test Set**
<img src="src/results/figures/confusion_matrix_use_test.png" width="500"/>

### ğŸ”¬ğŸ§  Conv1D Neural Network Model

The Conv1D text-classification model further improves performance across most classes, showing stronger generalization on large biomedical text sets.

#### âœ… Classification Metrics
| Class       | Precision | Recall | F1-Score | Support |
|-------------|----------:|-------:|--------:|--------:|
| BACKGROUND  | 0.51 | 0.69 | 0.59 | 2575 |
| CONCLUSIONS | 0.66 | 0.76 | 0.71 | 4396 |
| METHODS     | 0.88 | 0.88 | 0.88 | 9559 |
| OBJECTIVE   | 0.77 | 0.58 | 0.66 | 2425 |
| RESULTS     | 0.90 | 0.81 | 0.85 | 9977 |
| **Accuracy** | â€” | â€” | **0.80** | **28932** |

### ğŸ“ˆ Learning Curve
<img src="src/results/figures/learning_curve_conv1d.png" width="500"/>

### ğŸ”µ Confusion Matrix (Test Set)
<img src="src/results/figures/confusion_matrix_conv1d_test.png" width="500"/>


## ğŸ› ï¸ Roadmap

â€¢	Move current Colab code into src/ modules

â€¢	Add CLI args & config (YAML) for experiments

â€¢	Save trained models (artifacts/)

â€¢	Add tests for preprocessing

â€¢	Add Dockerfile + GitHub Actions (CI)

â€¢	Extend to domain-specific transformers (BioBERT, PubMedBERT)

## ğŸ“š Cite / Thesis

If you use this repository in academic work, please cite the accompanying thesis:
Georgakopoulos I. (2024). Development of an Effective and Comprehensive Information Retrieval Method for the Impact of Biological Factors on Patients with Inflammatory Bowel Diseases using Data Mining Techniques. National and Kapodistrian University of Athens.

## ğŸ”– License

This project is licensed under the MIT License. See LICENSE.

## ğŸ™ Acknowledgments

â€¢	PubMed 200k RCT dataset authors

â€¢	Open-source libraries: scikit-learn, TensorFlow, TensorFlow Hub, NLTK, Matplotlib/Seaborn

